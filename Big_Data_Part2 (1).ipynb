{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec87854-de93-4192-8062-ec9c77836953",
   "metadata": {},
   "source": [
    "# Install required liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b15dcf-fc6d-41f1-8fe2-ceafd541e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update pip (Skip if ERROR)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd07477-ded6-4bdf-bbf9-b3ce5d4cbeb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Pandas\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0e5bae-3d8f-477c-8874-ea8e5a615bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274e26d0-2670-4045-ae45-1333d9bd85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from vaderSentiment) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->vaderSentiment) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->vaderSentiment) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#VaderSentiment\n",
    "\n",
    "%pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0655c4-1c2a-474a-9866-d71217cd07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7a12fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab) (7.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab) (5.9.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab) (25.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab) (80.9.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab) (6.5.2)\n",
      "Requirement already satisfied: traitlets in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (9.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab) (7.1.3)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab) (0.29.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-core->jupyterlab) (4.5.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->jupyterlab) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: cffi>=2.0.0b1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from cffi>=2.0.0b1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.15.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde0172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: notebook in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (7.5.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from notebook) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from notebook) (2.28.0)\n",
      "Requirement already satisfied: jupyterlab<4.6,>=4.5.0rc0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from notebook) (4.5.0)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from notebook) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from notebook) (6.5.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.11.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.9.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.10.4)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.14.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.9.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab<4.6,>=4.5.0rc0->notebook) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab<4.6,>=4.5.0rc0->notebook) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyterlab<4.6,>=4.5.0rc0->notebook) (7.1.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab<4.6,>=4.5.0rc0->notebook) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab<4.6,>=4.5.0rc0->notebook) (80.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->notebook) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (9.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (7.1.3)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->notebook) (0.29.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook) (4.5.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (6.0.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->notebook) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.28.0->notebook) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.3.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.6,>=4.5.0rc0->notebook) (0.2.3)\n",
      "Requirement already satisfied: cffi>=2.0.0b1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from cffi>=2.0.0b1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.15.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.4.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1cf0f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.9.4.tar.gz (27.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\livam\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from wordcloud) (2.3.5)\n",
      "Collecting pillow (from wordcloud)\n",
      "  Using cached pillow-12.0.0-cp314-cp314-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting matplotlib (from wordcloud)\n",
      "  Using cached matplotlib-3.10.7-cp314-cp314-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->wordcloud)\n",
      "  Using cached contourpy-1.3.3-cp314-cp314-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->wordcloud)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->wordcloud)\n",
      "  Using cached fonttools-4.61.0-cp314-cp314-win_amd64.whl.metadata (115 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->wordcloud)\n",
      "  Using cached kiwisolver-1.4.9-cp314-cp314-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Collecting pyparsing>=3 (from matplotlib->wordcloud)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\livam\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp314-cp314-win_amd64.whl (8.3 MB)\n",
      "Using cached contourpy-1.3.3-cp314-cp314-win_amd64.whl (232 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.0-cp314-cp314-win_amd64.whl (2.3 MB)\n",
      "Using cached kiwisolver-1.4.9-cp314-cp314-win_amd64.whl (75 kB)\n",
      "Using cached pillow-12.0.0-cp314-cp314-win_amd64.whl (7.1 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (pyproject.toml): started\n",
      "  Building wheel for wordcloud (pyproject.toml): finished with status 'error'\n",
      "Failed to build wordcloud\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for wordcloud (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [44 lines of output]\n",
      "      C:\\Users\\livam\\AppData\\Local\\Temp\\pip-build-env-4lqvaymy\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "      \n",
      "              By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        corresp(dist, value, root_dir)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\tokenization.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\_version.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\__init__.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\__main__.py -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      running egg_info\n",
      "      writing wordcloud.egg-info\\PKG-INFO\n",
      "      writing dependency_links to wordcloud.egg-info\\dependency_links.txt\n",
      "      writing entry points to wordcloud.egg-info\\entry_points.txt\n",
      "      writing requirements to wordcloud.egg-info\\requires.txt\n",
      "      writing top-level names to wordcloud.egg-info\\top_level.txt\n",
      "      listing git files failed - pretending there aren't any\n",
      "      reading manifest file 'wordcloud.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no previously-included files found matching 'wordcloud\\TODO'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'wordcloud.egg-info\\SOURCES.txt'\n",
      "      copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\query_integral_image.c -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\query_integral_image.pyx -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      copying wordcloud\\stopwords -> build\\lib.win-amd64-cpython-314\\wordcloud\n",
      "      running build_ext\n",
      "      building 'wordcloud.query_integral_image' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for wordcloud\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: failed-wheel-build-for-install\n",
      "\n",
      "× Failed to build installable wheels for some pyproject.toml based projects\n",
      "╰─> wordcloud\n"
     ]
    }
   ],
   "source": [
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b78d1-95c7-41a3-84f9-e8c0d326cbf9",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ecdd56-e78c-4054-9f37-6da067cc641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running successful\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('kens_comments.csv')\n",
    "print(\"Running successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8207c47a-885b-4bec-b9cc-068fe9559e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5828, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38346a47-f41a-498e-ae63-2d0f1333c528",
   "metadata": {},
   "source": [
    "# Understand Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8171bd5-f9c1-48d8-8ca8-b9d029093fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has no missing values\n"
     ]
    }
   ],
   "source": [
    "#Checking for missing values and counting them\n",
    "if data.isnull().values.any():\n",
    "    print(\"The dataset has \", data.isnull().sum().sum(), \" missing value(s)\")\n",
    "    print(\"Here is the number of missing values for each column:\\n\", data.isnull().sum())\n",
    "else:\n",
    "    print(\"The dataset has no missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d666a89-6a3a-4607-9937-f761282fe7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "#Checking for douplicate values in the combined dataset and counting them\n",
    "if data.duplicated().values.any():\n",
    "    print(\"The dataset has \", combined_data.duplicated().sum(), \" duplicate rows\")\n",
    "else:\n",
    "    print(\"The dataset has no duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "774646ac-8216-4435-9308-eba72abbd896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0             int64\n",
      "comment               object\n",
      "comment_id            object\n",
      "author_url            object\n",
      "author_name           object\n",
      "reply_count            int64\n",
      "like_count             int64\n",
      "date                  object\n",
      "vidid                 object\n",
      "total_reply_counts     int64\n",
      "vid_title             object\n",
      "just_date             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Column names + data types\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 2)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e439dcc-3ff7-4167-94e3-10a0f8b2c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Unnamed: 0                                            comment  \\\n",
      "0              0  Kaggle - recommended website for datasets, lea...   \n",
      "1              1  I have a hard dilemma, where I graduated while...   \n",
      "...          ...                                                ...   \n",
      "5826        5826  Great video! Can you please post the github li...   \n",
      "5827        5827  Hi Ken\\n\\nI've been researching about this. Wo...   \n",
      "\n",
      "                      comment_id  \\\n",
      "0     UgwxUj8KPWyvC0tSLLZ4AaABAg   \n",
      "1     Ugx8dhVY59GFjtar8vR4AaABAg   \n",
      "...                          ...   \n",
      "5826  UgyhJTCKn88b0lggR794AaABAg   \n",
      "5827  UgzG1dz-KieX_gxjMWd4AaABAg   \n",
      "\n",
      "                                             author_url         author_name  \\\n",
      "0     http://www.youtube.com/channel/UCHYjrSUwq_OTrk...        Kim Jennifer   \n",
      "1     http://www.youtube.com/channel/UCgju1IU3hGdpc1...         James Hizon   \n",
      "...                                                 ...                 ...   \n",
      "5826  http://www.youtube.com/channel/UCazvqH3TM4OhJq...  Papurzin Trafalete   \n",
      "5827  http://www.youtube.com/channel/UCOTrNy9kY6HdBd...           karthik d   \n",
      "\n",
      "      reply_count  like_count                       date        vidid  \\\n",
      "0               0           0  2020-11-26 05:31:56+00:00  4OZip0cgOho   \n",
      "1               0           0  2020-11-26 04:58:17+00:00  T77uVbLhroQ   \n",
      "...           ...         ...                        ...          ...   \n",
      "5826            0           0  2018-02-20 16:46:19+00:00  qfRhKHV8-t4   \n",
      "5827            6           2  2017-12-03 18:52:35+00:00  qfRhKHV8-t4   \n",
      "\n",
      "      total_reply_counts                                          vid_title  \\\n",
      "0                      0  How I Would Learn Data Science (If I Had to St...   \n",
      "1                      0  How I Got My First Data Science Internship (An...   \n",
      "...                  ...                                                ...   \n",
      "5826                   0  Predicting Crypto-Currency Price Using RNN lST...   \n",
      "5827                   6  Predicting Crypto-Currency Price Using RNN lST...   \n",
      "\n",
      "       just_date  \n",
      "0     2020-11-26  \n",
      "1     2020-11-26  \n",
      "...          ...  \n",
      "5826  2018-02-20  \n",
      "5827  2017-12-03  \n",
      "\n",
      "[5828 rows x 12 columns]>\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', 42)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbf034d7-b8ae-4298-b41c-3bfca624a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                            5\n",
      "comment               Any good data sets for a time series project? ...\n",
      "comment_id                                   Ugxd5C8WoLDCyGiHFF54AaABAg\n",
      "author_url            http://www.youtube.com/channel/UCh5WvQaSQk2Wi7...\n",
      "author_name                                             theonlyone522 -\n",
      "reply_count                                                           0\n",
      "like_count                                                            0\n",
      "date                                          2020-11-25 19:34:51+00:00\n",
      "vidid                                                       8igH8qZafpo\n",
      "total_reply_counts                                                    0\n",
      "vid_title             3 Proven Data Science Projects for Beginners (...\n",
      "just_date                                                    2020-11-25\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Read single row\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 2)\n",
    "print(data.iloc[5]) # Change number for another row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f65f340c-220f-4d8e-aa76-60cbad0446a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             vid_title  num_comments\n",
      "0    How I Would Learn Data Science (If I Had to St...           606\n",
      "1    The Best Free Data Science Courses Nobody is T...           210\n",
      "2            Why I'm Starting Data Science Over Again.           189\n",
      "3    3 Proven Data Science Projects for Beginners (...           152\n",
      "4    Data Science Certificate vs Bootcamp vs Master...           150\n",
      "5    Building a Deep Learning BEAST (NVIDIA TITAN R...           149\n",
      "6    Data Science Project from Scratch - Part 2 (Da...           128\n",
      "7    Scrape Twitter Data in Python with Twitterscra...           122\n",
      "8    5 Essential Data Science Projects for Your Por...           112\n",
      "9    Beginner Kaggle Data Science Project Walk-Thro...           107\n",
      "10   Data Science Project from Scratch - Part 3 (Da...            84\n",
      "11   The Projects You Should Do To Get A Data Scien...            80\n",
      "12                          How I Learned Data Science            74\n",
      "13   The REAL Reason You're Struggling to Learn Dat...            73\n",
      "14   How to Make A Data Science Portfolio Website w...            69\n",
      "15   How to Build a Data Science Portfolio Website ...            67\n",
      "16   How I Learn Data Science Through Studying Othe...            64\n",
      "17    3 Reasons You Should NOT Become a Data Scientist            64\n",
      "18   Data Science Project from Scratch - Part 4 (Ex...            63\n",
      "19              The Plagiarism Problem in Data Science            63\n",
      "20                   Sh*t Data Scientists Say (Parody)            62\n",
      "21   Different Data Science Roles Explained (by a D...            62\n",
      "22              Math Needed for Mastering Data Science            62\n",
      "23                  The 5 Pillars of Success I Live By            59\n",
      "24                               Don't Buy My Course..            58\n",
      "25                      How to ULTRALEARN Data Science            58\n",
      "26   The State of Data Science with Krish Naik & Th...            58\n",
      "27   How I Chose My Masters Degree for Breaking int...            57\n",
      "28   How a Subscriber Landed a Data Analyst Job in ...            56\n",
      "29   10000 Subscriber and 100th Video Special (Data...            55\n",
      "30             How YOU Can Land a Sports Analytics Job            51\n",
      "31   Data Science Project from Scratch - Part 1 (Pr...            51\n",
      "32            Data Science Advice for College Students            50\n",
      "33   Reviewing Your Data Science Projects - Episode...            50\n",
      "34                Where to Start Learning Data Science            49\n",
      "35   Dealing with Doubt in Data Science (My Imposto...            49\n",
      "36        The Best Computer for Data Science Beginners            47\n",
      "37   The YouTube Algorithm EXPLAINED! (Tips from a ...            44\n",
      "38   What It's Like to be a Socially Distanced Data...            43\n",
      "39   Uber Driver to Machine Learning Engineer in 9 ...            43\n",
      "40   Data Science Project from Scratch - Part 7 (Do...            41\n",
      "41   The Secret Data Scientists Don't Want You to Know            41\n",
      "42   Data Science Project from Scratch  - Part 5 (M...            40\n",
      "43               Critiquing MY OWN Data Science Resume            40\n",
      "44   5 Proven Strategies to Break into a Data Scien...            39\n",
      "45   Interview with the Director of AI Research @ N...            39\n",
      "46   Inside the Mind of the Ultimate Kaggle Grandma...            38\n",
      "47   My First Data Science Contracting Side-Gig (Ho...            36\n",
      "48   Find a Data Science Project With These 3 Techn...            36\n",
      "49                      Is Data Science Right For You?            36\n",
      "50                        6 Lessons from #66DaysOfData            36\n",
      "51     git for Data Science Made Simple... (Hopefully)            35\n",
      "52   Reviewing Your Data Science Projects - Episode...            34\n",
      "53   Reviewing Your Data Science Projects - Episode...            34\n",
      "54      Work From Home Data Scientist: Day in the Life            33\n",
      "55   How She Dominated the FAANG Data Science Inter...            33\n",
      "56   Reviewing Your Data Science Projects - Episode...            32\n",
      "57   How to Get a Data Science Job at FAANG (@Data ...            31\n",
      "58   Reviewing Your Data Science Projects - Episode...            30\n",
      "59   5 Unusual Data Science Projects that Will Land...            30\n",
      "60   Data Science Project from Scratch -  Part 6 (P...            30\n",
      "61   Should You Major in Data Science? (Jaemin Lee)...            30\n",
      "62               The PODCAST you might have asked for?            30\n",
      "63   7 Things to Look For in a Masters For Data Sci...            29\n",
      "64           Should You Get A Masters in Data Science?            29\n",
      "65   How I Got My First Data Science Internship (An...            27\n",
      "66   Reviewing Your Data Science Projects - Episode...            26\n",
      "67   Data Science Resume Round-Up With @Tina Huang ...            26\n",
      "68   Reviewing Your Data Science Resumes - Episode ...            26\n",
      "69   Why Data-Viz is so Darn Important (@Story by D...            26\n",
      "70   Reviewing Your Data Science Projects - Episode...            25\n",
      "71               The 5 Stages of Learning Data Science            25\n",
      "72   Data Science Resume Round-Up With @Tina Huang ...            25\n",
      "73   9 Ways You Can Make Extra Income as a Data Sci...            25\n",
      "74   How to Scrape NBA Data Using the nba_api Pytho...            25\n",
      "75   Reviewing Your Data Science Projects - Episode...            23\n",
      "76   Reviewing Your Data Science Projects - Episode...            23\n",
      "77   Reviewing Your Data Science Projects - Episode...            23\n",
      "78     Ken Jee Q & A Live Stream (50,000 Sub Special!)            23\n",
      "79   Reviewing Your Data Science Projects - Episode...            23\n",
      "80   Advice from a Data Analytics CEO (@How to Get ...            22\n",
      "81   Reviewing Your Data Science Projects - Episode...            22\n",
      "82   How To Get Data Science Experience (Without a ...            22\n",
      "83   How to Set Up Your Data Science Environment (A...            21\n",
      "84   His Startup Will Land You a Data Science Job (...            21\n",
      "85   What You Need to Know for a Data Science Inter...            20\n",
      "86   I Wish I Had Known THIS Before Starting in Dat...            20\n",
      "87   Reviewing Your Data Science Projects - Episode...            20\n",
      "88   Why Right NOW is a Great Time to Learn Data Sc...            20\n",
      "89   How To Learn Programming for Data Science [3 S...            20\n",
      "90   Land a Data Science Job in a Different Country...            20\n",
      "91   Reviewing Your Data Science Projects - Episode...            20\n",
      "92           Avoid These Data Science Resume Mistakes!            19\n",
      "93   Data Science Fundamentals: Data Exploration in...            19\n",
      "94   Reviewing Your Data Science Projects - Episode...            18\n",
      "95   Predicting Crypto-Currency Price Using RNN lST...            18\n",
      "96   Reviewing Your Data Science Projects - Episode...            18\n",
      "97   Reviewing Your Data Science Projects - Episode...            17\n",
      "98   Data Science Project Example Start to Finish (...            17\n",
      "99   Data Science Fundamentals: Data Cleaning in Py...            17\n",
      "100  Do You Have a Data Science Mentor? (@Danny Ma)...            16\n",
      "101  Data Science Fundamentals: Data Manipulation i...            16\n",
      "102  Data Science Productivity, Motivation, and Org...            15\n",
      "103  Reviewing Your Projects - Episode 16 (Project ...            15\n",
      "104  Sports Analytics & Streaming Data Science on T...            15\n",
      "105  Reviewing Your Data Science Projects - Episode...            15\n",
      "106               Should You Learn R for Data Science?            14\n",
      "107  Reviewing Your Data Science Projects - Episode...            14\n",
      "108                How to Simulate NBA Games in Python            14\n",
      "109  Hedge Funds, Startups, and Data Science Oh my!...            14\n",
      "110  Is it Important to Share Your Data Science Wor...            14\n",
      "111  How to Stay Productive & Motivated When Learni...            14\n",
      "112        5 Sports Analytics Books to Get You Started            14\n",
      "113        5 Tips for Crushing the Work From Home Life            13\n",
      "114  Thank You For The Support | What's Next | Ken ...            12\n",
      "115       Data Science Fundamentals: Linear Regression            12\n",
      "116  Fast Cars to Faster Data (Alex Castrounis) - K...            12\n",
      "117           Data Science Explained with ... Cooking?            11\n",
      "118        The Data Science Projects that Got Me a Job            11\n",
      "119                   What is Sports Analytics Really?            11\n",
      "120             Data Science Fundamentals: SQL Queries            11\n",
      "121            What Does a Data Scientist Actually Do?            10\n",
      "122                  100K Channel Update + AMA Stream!            10\n",
      "123    The 9 Books That Changed My Perspective in 2019            10\n",
      "124                       When Data Science Goes Wrong             9\n",
      "125           The 4 Types of Sports Analytics Projects             9\n",
      "126                        Data Science: Pros and Cons             9\n",
      "127   How to Integrate Data Science into Your Business             8\n",
      "128  Data Science in Sports - Talk for Northwestern...             8\n",
      "129   How Far Should the NBA 3-Point Line Actually Be?             8\n",
      "130  Applying Data Science To My YouTube Data: My S...             8\n",
      "131    Collision Course: Sports Betting + Data Science             8\n",
      "132  Sports Analytics 101: The Pythagorean Theorem ...             7\n",
      "133  Was Captain Marvel Bad? A Sentiment Analysis o...             7\n",
      "134  How Much Did Cheating Help the Astros Win? (Wh...             7\n",
      "135  How I Became A Data Scientist From a Business ...             6\n",
      "136               What I Learned From My Three Degrees             6\n",
      "137              The 5 Stages of Data Science Adoption             6\n",
      "138  Data Science, Machine Learning, and AI: What's...             6\n",
      "139         The Data Science Interview: What to Expect             6\n",
      "140                      The Problem with Data Science             5\n",
      "141                5 Data Science Resolutions for 2020             5\n",
      "142  Where YOU Should Start With Data Science Projects             5\n",
      "143    Watch This Before Applying to Data Science Jobs             5\n",
      "144              My Top 5 Data Science Internship Tips             5\n",
      "145  By The Numbers: Where Should The NBA Put a 4 P...             4\n",
      "146          Why is Balance Important in Data Science?             4\n",
      "147  Take Your Data Science Projects From Good to G...             4\n",
      "148  Predicting Season Long NBA Wins Using Multiple...             4\n",
      "149           My Top 5 Data Science Resources for 2019             4\n",
      "150      Why You DON'T Want to be a WFH Data Scientist             4\n",
      "151         The Best Way to Predict NBA Minutes Played             4\n",
      "152             6 Habits of Successful Data Scientists             3\n",
      "153     Can You Learn Data Science Without a Computer?             3\n",
      "154    Data Science in Golf: PGA Merchandise Show 2020             3\n",
      "155                Where to Look for Data Science Jobs             3\n",
      "156     Why Selling Is An Important Data Science Skill             3\n",
      "157  Golf: Would You Rather Be the LONGEST or STRAI...             3\n",
      "158  NASA Physicist Turned Data Scientist (Tim Bowl...             2\n",
      "159               Golf STATS: Strokes Gained Explained             2\n",
      "160  Questions You Should Ask Your Data Science Int...             2\n",
      "161     Welcome To My Channel | Ken Jee | Data Science             2\n",
      "162  Most Data Science Hopefuls Overlook This Impor...             1\n",
      "163                   IT'S NOT TOO LATE TO LEARN CODE!             1\n",
      "164                    Demystifying Data Science Roles             1\n",
      "165  How To Build A Word Cloud From Scraped Data (P...             1\n"
     ]
    }
   ],
   "source": [
    "# Count number of comments per video (overview)\n",
    "\n",
    "video_comment_counts = (\n",
    "    data.groupby('vid_title')\n",
    "        .size()\n",
    "        .reset_index(name='num_comments')\n",
    "        .sort_values(by='num_comments', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "pd.set_option('display.max_rows', 170)\n",
    "pd.set_option('display.max_columns', 2)\n",
    "print(video_comment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f7b4f-2d43-4f7c-bbc1-e4091e299962",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df289104-6928-4e45-8f05-7b365d3a2a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                        vid_title  \\\n",
      "0                                         How I Would Learn Data Science (If I Had to Start Over)   \n",
      "1                                      The Best Free Data Science Courses Nobody is Talking About   \n",
      "2                                                       Why I'm Starting Data Science Over Again.   \n",
      "3                                           3 Proven Data Science Projects for Beginners (Kaggle)   \n",
      "4                                          Data Science Certificate vs Bootcamp vs Masters Degree   \n",
      "5                                 Building a Deep Learning BEAST (NVIDIA TITAN RTX + RYZEN 3900X)   \n",
      "6                                    Data Science Project from Scratch - Part 2 (Data Collection)   \n",
      "7                                        Scrape Twitter Data in Python with Twitterscraper Module   \n",
      "8                                            5 Essential Data Science Projects for Your Portfolio   \n",
      "9                                     Beginner Kaggle Data Science Project Walk-Through (Titanic)   \n",
      "10                                     Data Science Project from Scratch - Part 3 (Data Cleaning)   \n",
      "11                                           The Projects You Should Do To Get A Data Science Job   \n",
      "12                                                                     How I Learned Data Science   \n",
      "13                                        The REAL Reason You're Struggling to Learn Data Science   \n",
      "14                                 How to Make A Data Science Portfolio Website with Github Pages   \n",
      "15  How to Build a Data Science Portfolio Website with Hugo & Github Pages [feat. Data Professor]   \n",
      "16                  How I Learn Data Science Through Studying Other People's Code | #66DaysOfData   \n",
      "17                                               3 Reasons You Should NOT Become a Data Scientist   \n",
      "18                                                         The Plagiarism Problem in Data Science   \n",
      "19                         Data Science Project from Scratch - Part 4 (Exploratory Data Analysis)   \n",
      "20                                   Different Data Science Roles Explained (by a Data Scientist)   \n",
      "21                                                         Math Needed for Mastering Data Science   \n",
      "22                                                              Sh*t Data Scientists Say (Parody)   \n",
      "23                                                             The 5 Pillars of Success I Live By   \n",
      "24              The State of Data Science with Krish Naik & The Data Professor [Panel Discussion]   \n",
      "25                                                                          Don't Buy My Course..   \n",
      "26                                                                 How to ULTRALEARN Data Science   \n",
      "27                                   How I Chose My Masters Degree for Breaking into Data Science   \n",
      "28         How a Subscriber Landed a Data Analyst Job in Less Than a Year (Ray Ojel) - KNN EP. 09   \n",
      "29                                        10000 Subscriber and 100th Video Special (Data Science)   \n",
      "30                                                        How YOU Can Land a Sports Analytics Job   \n",
      "31                                  Data Science Project from Scratch - Part 1 (Project Planning)   \n",
      "32                                                       Data Science Advice for College Students   \n",
      "33                      Reviewing Your Data Science Projects - Episode 13 (BONUS LinkedIn Review)   \n",
      "\n",
      "    num_comments  \n",
      "0            606  \n",
      "1            210  \n",
      "2            189  \n",
      "3            152  \n",
      "4            150  \n",
      "5            149  \n",
      "6            128  \n",
      "7            122  \n",
      "8            112  \n",
      "9            107  \n",
      "10            84  \n",
      "11            80  \n",
      "12            74  \n",
      "13            73  \n",
      "14            69  \n",
      "15            67  \n",
      "16            64  \n",
      "17            64  \n",
      "18            63  \n",
      "19            63  \n",
      "20            62  \n",
      "21            62  \n",
      "22            62  \n",
      "23            59  \n",
      "24            58  \n",
      "25            58  \n",
      "26            58  \n",
      "27            57  \n",
      "28            56  \n",
      "29            55  \n",
      "30            51  \n",
      "31            51  \n",
      "32            50  \n",
      "33            50  \n",
      "This is the new shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3415, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete records with less than x comments per video\n",
    "# Define threshold\n",
    " \n",
    "x = 50\n",
    "# Count comments per video\n",
    " \n",
    "video_comment_counts = (\n",
    " \n",
    "    data.groupby('vid_title')\n",
    " \n",
    "        .size()\n",
    " \n",
    "        .reset_index(name='num_comments')\n",
    " \n",
    ")\n",
    "# Keep only videos with at least x comments\n",
    " \n",
    "valid_videos = video_comment_counts.loc[\n",
    " \n",
    "    video_comment_counts['num_comments'] >= x, 'vid_title'\n",
    " \n",
    "]\n",
    "# Filter the original dataset\n",
    " \n",
    "data2 = data[data['vid_title'].isin(valid_videos)].copy()\n",
    "# Count number of comments per video (overview)\n",
    "video_comment_counts2 = (\n",
    "    data2.groupby('vid_title')\n",
    "        .size()\n",
    "        .reset_index(name='num_comments')\n",
    "        .sort_values(by='num_comments', ascending=False)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "pd.set_option('display.max_columns', 2)\n",
    "print(video_comment_counts2)\n",
    "print(\"This is the new shape:\")\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e02bcd4-7c96-4c05-be40-35ff97faa826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4527 positive comments to kens_positive_comments.csv\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def pip_install(package):\n",
    "    print(f\"Installing {package} into {sys.executable} ...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Ensure nltk and pandas are installed\n",
    "for pkg in [\"nltk\", \"pandas\"]:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ImportError:\n",
    "        pip_install(pkg)\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure VADER lexicon is available\n",
    "try:\n",
    "    nltk.data.find(\"sentiment/vader_lexicon.zip\")\n",
    "except LookupError:\n",
    "    print(\"Downloading vader_lexicon...\")\n",
    "    nltk.download(\"vader_lexicon\", quiet=True)\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def filter_positive_from_csv(input_csv, output_csv, text_column=\"comment\", threshold=0.05):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found. Columns available: {list(df.columns)}\")\n",
    "\n",
    "    # Apply VADER sentiment\n",
    "    df[\"compound\"] = df[text_column].astype(str).apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "    # Filter positive comments\n",
    "    df_positive = df[df[\"compound\"] >= threshold]\n",
    "\n",
    "    # Save results\n",
    "    df_positive.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved {len(df_positive)} positive comments to {output_csv}\")\n",
    "\n",
    "# --------- RUN HERE ---------\n",
    "\n",
    "filter_positive_from_csv(\n",
    "    input_csv=\"kens_comments.csv\",\n",
    "    output_csv=\"kens_positive_comments.csv\",\n",
    "    text_column=\"comment\",   # <-- change this if your column name is different\n",
    "    threshold=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6d38e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f940ca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaggle - recommended website for datasets, learning data science</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you for continuing to share and add to the community. I started Kaggle and you make a lot of good points about the benefits for the short and long run with it.</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awesome tutorial. I have a question. Why do you log normalize Sibsp and Fare in addition to using StandardScaler? What does the log normalization accomplish that the StandardScaler doesn't?</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Any good data sets for a time series project? Or anomaly detection?</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sir, could you please tell me about the background music being used .its so motivating and it gives me a pump for pushing myself forward.</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                         comment  \\\n",
       "0                                                                                                                               Kaggle - recommended website for datasets, learning data science   \n",
       "2                          Thank you for continuing to share and add to the community. I started Kaggle and you make a lot of good points about the benefits for the short and long run with it.   \n",
       "3  Awesome tutorial. I have a question. Why do you log normalize Sibsp and Fare in addition to using StandardScaler? What does the log normalization accomplish that the StandardScaler doesn't?   \n",
       "5                                                                                                                            Any good data sets for a time series project? Or anomaly detection?   \n",
       "7                                                      sir, could you please tell me about the background music being used .its so motivating and it gives me a pump for pushing myself forward.   \n",
       "\n",
       "   ...  sentiment  \n",
       "0  ...   positive  \n",
       "2  ...   positive  \n",
       "3  ...   positive  \n",
       "5  ...   positive  \n",
       "7  ...   positive  \n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vader_scores(text):\n",
    "    if isinstance(text, str):\n",
    "        return analyzer.polarity_scores(text)\n",
    "    else:\n",
    "        return {\"neg\": 0, \"neu\": 0, \"pos\": 0, \"compound\": 0}\n",
    " \n",
    "scores = data2['comment'].apply(vader_scores).apply(pd.Series)\n",
    "data3 = pd.concat([data2, scores], axis=1)\n",
    "\n",
    "def label_sentiment(c):\n",
    "    if c >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    " \n",
    "data3['sentiment'] = data3['compound'].apply(label_sentiment)\n",
    "\n",
    "data3[['comment', 'neg', 'neu', 'pos', 'compound', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df34020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_scores(text):\n",
    "    if isinstance(text, str):\n",
    "        return analyzer.polarity_scores(text)\n",
    "    else:\n",
    "        return {\"neg\": 0, \"neu\": 0, \"pos\": 0, \"compound\": 0}\n",
    " \n",
    "scores = data2['comment'].apply(vader_scores).apply(pd.Series)\n",
    "data3 = pd.concat([data2, scores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95df6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(c):\n",
    "    if c >= 0.55:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.001:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    " \n",
    "data3['sentiment'] = data3['compound'].apply(label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61302be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    1849\n",
      "neutral     1319\n",
      "negative     247\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data3[['comment', 'neg', 'neu', 'pos', 'compound', 'sentiment']].head()\n",
    "\n",
    "sentiment_counts = data3['sentiment'].value_counts()\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3a024ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data3 from highest to lowest compound score\n",
    "data3_sorted = data3.sort_values(by=\"compound\", ascending=False)\n",
    " \n",
    "# Save to CSV\n",
    "data3_sorted.to_csv(\"data3_sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d77f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Results =====\n",
      "👍 Best video (highest % positive): 10000 Subscriber and 100th Video Special (Data Science)\n",
      "👎 Video with most negative impact: Scrape Twitter Data in Python with Twitterscraper Module\n"
     ]
    }
   ],
   "source": [
    "# count how many negative and positive comments a video has + scoring of videos (%) \n",
    "# Which video was the best and which video has the most negative impact? \n",
    "\n",
    "video_sentiment_counts = (\n",
    "    data3.groupby([\"vid_title\", \"sentiment\"])\n",
    "         .size()\n",
    "         .unstack(fill_value=0)\n",
    "         .reset_index()\n",
    ")\n",
    "\n",
    "# ensure missing categories don't break the table\n",
    "for col in [\"positive\", \"negative\", \"neutral\"]:\n",
    "    if col not in video_sentiment_counts.columns:\n",
    "        video_sentiment_counts[col] = 0\n",
    "\n",
    "# calculates percentage\n",
    "video_sentiment_counts[\"total_comments\"] = (\n",
    "    video_sentiment_counts[\"positive\"] +\n",
    "    video_sentiment_counts[\"negative\"] +\n",
    "    video_sentiment_counts[\"neutral\"]\n",
    ")\n",
    "\n",
    "video_sentiment_counts[\"positive_%\"] = (\n",
    "    video_sentiment_counts[\"positive\"] /\n",
    "    video_sentiment_counts[\"total_comments\"] * 100\n",
    ")\n",
    "\n",
    "video_sentiment_counts[\"negative_%\"] = (\n",
    "    video_sentiment_counts[\"negative\"] /\n",
    "    video_sentiment_counts[\"total_comments\"] * 100\n",
    ")\n",
    "\n",
    "# find best and worst video\n",
    "best_video = video_sentiment_counts.loc[\n",
    "    video_sentiment_counts[\"positive_%\"].idxmax(), \"vid_title\"\n",
    "]\n",
    "\n",
    "worst_video = video_sentiment_counts.loc[\n",
    "    video_sentiment_counts[\"negative_%\"].idxmax(), \"vid_title\"\n",
    "]\n",
    "\n",
    "# result\n",
    "print(\"\\n===== Results =====\")\n",
    "print(f\"👍 Best video (highest % positive): {best_video}\")\n",
    "print(f\"👎 Video with most negative impact: {worst_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "487c5fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# wordcloud for one of the videos with the most positive comments\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# What is the wordcloud of the \"positive comments\" for the video with the most positive comments? \u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# wordcloud for one of the videos with the most negative comments\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# What is the wordcloud of the \"negative comments\" for the video with the most negative comments? \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwordcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_wordcloud\u001b[39m(text, title):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# wordcloud for one of the videos with the most positive comments\n",
    "# What is the wordcloud of the \"positive comments\" for the video with the most positive comments? \n",
    "\n",
    "# wordcloud for one of the videos with the most negative comments\n",
    "# What is the wordcloud of the \"negative comments\" for the video with the most negative comments? \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400, \n",
    "        background_color='white', \n",
    "        colormap='viridis'\n",
    "    ).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# wordcloud - positive comments\n",
    "most_positive_video = best_video\n",
    "positive_comments = data3[\n",
    "    (data3['vid_title'] == most_positive_video) & \n",
    "    (data3['sentiment'] == 'positive')\n",
    "]['comment'].dropna().str.cat(sep=' ')\n",
    "\n",
    "generate_wordcloud(positive_comments, f\"Positive Comments WordCloud for '{most_positive_video}'\")\n",
    "\n",
    "# wordcloud - negative comments \n",
    "most_negative_video = worst_video\n",
    "negative_comments = data3[\n",
    "    (data3['vid_title'] == most_negative_video) & \n",
    "    (data3['sentiment'] == 'negative')\n",
    "]['comment'].dropna().str.cat(sep=' ')\n",
    "\n",
    "generate_wordcloud(negative_comments, f\"Negative Comments WordCloud for '{most_negative_video}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2aa09-b0cc-43c6-a9db-88b45c38f146",
   "metadata": {},
   "source": [
    "# Source data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add4e85e-ad64-4236-8031-3606a348d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/hellotinah/youtube_sentiment_analysis/blob/main/kens_comments.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
